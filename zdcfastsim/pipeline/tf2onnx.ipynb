{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "399a3e02",
   "metadata": {},
   "source": [
    "# Tensorflow models to onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d0f34f",
   "metadata": {},
   "source": [
    "Notebook with examples of conversions from tensorflow to onnx models. The tensorflow models were saved using the _save_weights_ (not _save_) function.  \n",
    "Note: the weights are not provided in the repository and this notebook should be treated as a guide showing how to convert a tensorflow model to onnx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94225762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf2onnx in /home/emilia/alice-code/venv/lib/python3.8/site-packages (1.12.0)\n",
      "Requirement already satisfied: onnx>=1.4.1 in /home/emilia/alice-code/venv/lib/python3.8/site-packages (from tf2onnx) (1.12.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12 in /home/emilia/alice-code/venv/lib/python3.8/site-packages (from tf2onnx) (1.12)\n",
      "Requirement already satisfied: six in /home/emilia/alice-code/venv/lib/python3.8/site-packages (from tf2onnx) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.14.1 in /home/emilia/alice-code/venv/lib/python3.8/site-packages (from tf2onnx) (1.23.0)\n",
      "Requirement already satisfied: requests in /home/emilia/alice-code/venv/lib/python3.8/site-packages (from tf2onnx) (2.28.1)\n",
      "Requirement already satisfied: protobuf<=3.20.1,>=3.12.2 in /home/emilia/alice-code/venv/lib/python3.8/site-packages (from onnx>=1.4.1->tf2onnx) (3.19.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /home/emilia/alice-code/venv/lib/python3.8/site-packages (from onnx>=1.4.1->tf2onnx) (4.3.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/emilia/alice-code/venv/lib/python3.8/site-packages (from requests->tf2onnx) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/emilia/alice-code/venv/lib/python3.8/site-packages (from requests->tf2onnx) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/emilia/alice-code/venv/lib/python3.8/site-packages (from requests->tf2onnx) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/emilia/alice-code/venv/lib/python3.8/site-packages (from requests->tf2onnx) (3.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/emilia/alice-code/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tf2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e6d630a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 20:53:58.046782: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-28 20:53:58.046815: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.compat.v1.keras.layers import Input, Dense, LeakyReLU, Conv2D, MaxPooling2D, UpSampling2D, Concatenate\n",
    "from tensorflow.compat.v1.keras.models import Model\n",
    "from tensorflow.compat.v1.keras.layers import Dense, Reshape, Flatten\n",
    "from tensorflow.compat.v1.keras.layers import Dropout, BatchNormalization\n",
    "from scipy.stats import wasserstein_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e8e6f9",
   "metadata": {},
   "source": [
    "# Protons VAE model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec591338",
   "metadata": {},
   "source": [
    "The tf2onnx library requires providing path to a saved model, with both architecture and weights. Therefore, it is needed to firstly build a model, load the weights and then save it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910c562",
   "metadata": {},
   "source": [
    "## Define model\n",
    "The model must have the same structure as the model which weights were saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab22ac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 10\n",
    "cond_dim = 9\n",
    "poz_dim = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8ee39fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 9)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 19)           0           ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 3584)         71680       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 7, 4, 128)    0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 14, 8, 128)   0           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 14, 8, 128)   262272      ['up_sampling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 14, 8, 128)  512         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 14, 8, 128)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 28, 16, 128)  0          ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 28, 16, 64)   131136      ['up_sampling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 28, 16, 64)  256         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 28, 16, 64)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 56, 32, 64)  0           ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 56, 32, 32)   32800       ['up_sampling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 56, 32, 32)  128         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 56, 32, 32)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 56, 30, 1)    97          ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 498,881\n",
      "Trainable params: 498,433\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 20:54:03.790269: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-09-28 20:54:03.790310: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-28 20:54:03.790341: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (nbemajerz): /proc/driver/nvidia/version does not exist\n",
      "2022-09-28 20:54:03.790903: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "x = Input(shape=(latent_dim,))\n",
    "cond = Input(shape=(cond_dim,))\n",
    "inputs = Concatenate(axis=1)([x, cond])\n",
    "\n",
    "g = Dense(7*4*128)(inputs)\n",
    "g = Reshape((7,4,128))(g)\n",
    "\n",
    "g = UpSampling2D()(g)\n",
    "g = Conv2D(128, kernel_size=4, padding='same')(g)\n",
    "g = BatchNormalization()(g)\n",
    "g = LeakyReLU(alpha=0)(g)\n",
    "\n",
    "g = UpSampling2D()(g)\n",
    "g = Conv2D(64, kernel_size=4, padding='same')(g)\n",
    "g = BatchNormalization()(g)\n",
    "g = LeakyReLU(alpha=0)(g)\n",
    "\n",
    "g = UpSampling2D()(g)\n",
    "g = Conv2D(32, kernel_size=4, padding='same')(g)\n",
    "g = BatchNormalization()(g)\n",
    "g = LeakyReLU(alpha=0)(g)\n",
    "\n",
    "outputs = Conv2D(1, kernel_size=(1,3) ,activation='relu')(g)\n",
    "\n",
    "generator = Model([x, cond], outputs, name='generator')\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "007fb519",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.load_weights('protons_vae/gen_protons_VAE_default_96.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7739a29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: generator-protons-vae/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: generator-protons-vae/assets\n",
      "WARNING:absl:<keras.layers.normalization.batch_normalization_v1.BatchNormalization object at 0x7ff2daa4ec40> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class 'keras.layers.normalization.batch_normalization_v1.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.normalization.batch_normalization_v1.BatchNormalization object at 0x7ff2d816f730> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class 'keras.layers.normalization.batch_normalization_v1.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.normalization.batch_normalization_v1.BatchNormalization object at 0x7ff2d8130df0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class 'keras.layers.normalization.batch_normalization_v1.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "generator.save('generator-protons-vae')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d5522b",
   "metadata": {},
   "source": [
    "### Now it is possible to actually convert the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfadaaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-28 20:55:41.735846: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-28 20:55:41.735874: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/usr/lib/python3.8/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2022-09-28 20:55:43.021842: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-09-28 20:55:43.021865: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-28 20:55:43.021880: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (nbemajerz): /proc/driver/nvidia/version does not exist\n",
      "2022-09-28 20:55:43.022084: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-28 20:55:43,023 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
      "2022-09-28 20:55:43,432 - INFO - Signatures found in model: [serving_default].\n",
      "2022-09-28 20:55:43,432 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
      "2022-09-28 20:55:43,433 - INFO - Output names: ['conv2d_3']\n",
      "2022-09-28 20:55:43.435455: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-09-28 20:55:43.435781: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "WARNING:tensorflow:From /home/emilia/alice-code/venv/lib/python3.8/site-packages/tf2onnx/tf_loader.py:711: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2022-09-28 20:55:43,563 - WARNING - From /home/emilia/alice-code/venv/lib/python3.8/site-packages/tf2onnx/tf_loader.py:711: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2022-09-28 20:55:43.566910: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-09-28 20:55:43.567071: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-09-28 20:55:43,612 - INFO - Using tensorflow=2.9.1, onnx=1.12.0, tf2onnx=1.12.0/a58786\n",
      "2022-09-28 20:55:43,612 - INFO - Using opset <onnx, 13>\n",
      "2022-09-28 20:55:43,753 - INFO - Computed 0 values for constant folding\n",
      "2022-09-28 20:55:43,856 - INFO - Optimizing ONNX model\n",
      "2022-09-28 20:55:43,943 - INFO - After optimization: BatchNormalization -3 (3->0), Cast -5 (5->0), Concat -1 (5->4), Const -34 (52->18), Identity -6 (6->0), Reshape +1 (1->2), Shape -1 (4->3), Slice -1 (4->3), Squeeze -1 (1->0), Transpose -19 (20->1), Unsqueeze -4 (4->0)\n",
      "2022-09-28 20:55:43,946 - INFO - \n",
      "2022-09-28 20:55:43,946 - INFO - Successfully converted TensorFlow model generator-protons-vae to ONNX\n",
      "2022-09-28 20:55:43,946 - INFO - Model inputs: ['input_1', 'input_2']\n",
      "2022-09-28 20:55:43,946 - INFO - Model outputs: ['conv2d_3']\n",
      "2022-09-28 20:55:43,946 - INFO - ONNX model is saved at generator-protons-vae.onnx\n"
     ]
    }
   ],
   "source": [
    "!python -m tf2onnx.convert --saved-model generator-protons-vae --output generator-protons-vae.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab5a70e",
   "metadata": {},
   "source": [
    "# ____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f6c38f",
   "metadata": {},
   "source": [
    "## Same for gan model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70439013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 9)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 19)           0           ['input_5[0][0]',                \n",
      "                                                                  'input_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 256)          5120        ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 256)         1024        ['dense_8[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 256)          0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)     (None, 256)          0           ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 21632)        5559424     ['leaky_re_lu_12[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 21632)       86528       ['dense_9[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 21632)        0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)     (None, 21632)        0           ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 13, 13, 128)  0           ['leaky_re_lu_13[0][0]']         \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 26, 26, 128)  0          ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 24, 24, 128)  147584      ['up_sampling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 24, 24, 128)  512        ['conv2d_7[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 24, 24, 128)  0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " leaky_re_lu_14 (LeakyReLU)     (None, 24, 24, 128)  0           ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 48, 48, 128)  0          ['leaky_re_lu_14[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 46, 46, 64)   73792       ['up_sampling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 46, 46, 64)  256         ['conv2d_8[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 46, 46, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " leaky_re_lu_15 (LeakyReLU)     (None, 46, 46, 64)   0           ['dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 44, 44, 1)    577         ['leaky_re_lu_15[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,874,817\n",
      "Trainable params: 5,830,657\n",
      "Non-trainable params: 44,160\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "########################### Define Models ############################\n",
    "latent_dim = 10\n",
    "cond_dim = 9\n",
    "\n",
    "############################ generator ############################\n",
    "\n",
    "x = Input(shape=(latent_dim,))\n",
    "cond = Input(shape=(cond_dim,))\n",
    "inputs = Concatenate(axis=1)([x, cond])\n",
    "layer_1 = Dense(128 * 2)(inputs)\n",
    "layer_1_bd = Dropout(0.2)(BatchNormalization()(layer_1))\n",
    "layer_1_a = LeakyReLU(alpha=0.1)(layer_1_bd)\n",
    "layer_2 = Dense(128 * 13 * 13)(layer_1_a)\n",
    "layer_2_bd = Dropout(0.2)(BatchNormalization()(layer_2))\n",
    "layer_2_a = LeakyReLU(alpha=0.1)(layer_2_bd)\n",
    "reshaped = Reshape((13, 13, 128))(layer_2_a)\n",
    "reshaped_s = UpSampling2D()(reshaped)\n",
    "conv1 = Conv2D(128, kernel_size=3)(reshaped_s)\n",
    "conv1_bd = Dropout(0.2)(BatchNormalization()(conv1))\n",
    "conv1_a = LeakyReLU(alpha=0.1)(conv1_bd)\n",
    "conv1_a_s = UpSampling2D()(conv1_a)\n",
    "conv2 = Conv2D(64, kernel_size=3)(conv1_a_s)\n",
    "conv2_bd = Dropout(0.2)(BatchNormalization()(conv2))\n",
    "conv2_a = LeakyReLU(alpha=0.1)(conv2_bd)\n",
    "outputs = Conv2D(1, kernel_size=3, activation='relu')(conv2_a)\n",
    "\n",
    "generator = Model([x, cond], outputs, name='generator')\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4cf1438",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.load_weights('gan1_neutrons_default/gen_gan_default_99.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91e9ea86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: generator-gan-default-neutrons/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: generator-gan-default-neutrons/assets\n",
      "WARNING:absl:<keras.layers.normalization.batch_normalization_v1.BatchNormalization object at 0x7ff9546f7880> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class 'keras.layers.normalization.batch_normalization_v1.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.normalization.batch_normalization_v1.BatchNormalization object at 0x7ff954680640> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class 'keras.layers.normalization.batch_normalization_v1.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.normalization.batch_normalization_v1.BatchNormalization object at 0x7ff9546f04f0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class 'keras.layers.normalization.batch_normalization_v1.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.normalization.batch_normalization_v1.BatchNormalization object at 0x7ff954695490> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class 'keras.layers.normalization.batch_normalization_v1.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "generator.save('generator-gan-default-neutrons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "071fffa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-30 15:05:13.537688: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-30 15:05:13.537737: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/usr/lib/python3.8/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2022-08-30 15:05:15.494850: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-30 15:05:15.494879: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-30 15:05:15.494899: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (nbemajerz): /proc/driver/nvidia/version does not exist\n",
      "2022-08-30 15:05:15.495158: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-30 15:05:15,497 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
      "2022-08-30 15:05:16,322 - INFO - Signatures found in model: [serving_default].\n",
      "2022-08-30 15:05:16,322 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
      "2022-08-30 15:05:16,322 - INFO - Output names: ['conv2d_9']\n",
      "2022-08-30 15:05:16.327145: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-08-30 15:05:16.327534: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "WARNING:tensorflow:From /home/emilia/alice-code/venv/lib/python3.8/site-packages/tf2onnx/tf_loader.py:711: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2022-08-30 15:05:16,835 - WARNING - From /home/emilia/alice-code/venv/lib/python3.8/site-packages/tf2onnx/tf_loader.py:711: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2022-08-30 15:05:16.841600: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-08-30 15:05:16.841787: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-08-30 15:05:17,154 - INFO - Using tensorflow=2.9.1, onnx=1.12.0, tf2onnx=1.12.0/a58786\n",
      "2022-08-30 15:05:17,154 - INFO - Using opset <onnx, 13>\n",
      "2022-08-30 15:05:19,527 - INFO - Computed 0 values for constant folding\n",
      "2022-08-30 15:05:20,918 - INFO - Optimizing ONNX model\n",
      "2022-08-30 15:05:21,110 - INFO - After optimization: BatchNormalization -2 (2->0), Cast -4 (4->0), Concat -1 (4->3), Const -26 (47->21), Identity -10 (10->0), Reshape +1 (1->2), Shape -1 (3->2), Slice -1 (3->2), Squeeze -1 (1->0), Transpose -13 (14->1), Unsqueeze -4 (4->0)\n",
      "2022-08-30 15:05:21,134 - INFO - \n",
      "2022-08-30 15:05:21,134 - INFO - Successfully converted TensorFlow model generator-gan-default-neutrons to ONNX\n",
      "2022-08-30 15:05:21,134 - INFO - Model inputs: ['input_5', 'input_6']\n",
      "2022-08-30 15:05:21,134 - INFO - Model outputs: ['conv2d_9']\n",
      "2022-08-30 15:05:21,134 - INFO - ONNX model is saved at generator-gan-default-neutrons.onnx\n"
     ]
    }
   ],
   "source": [
    "!python -m tf2onnx.convert --saved-model generator-gan-default-neutrons --output generator-gan-default-neutrons.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49582146",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
